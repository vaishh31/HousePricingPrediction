{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa56cf-8a7f-4fbf-b7a7-6aed369e87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# LoadING THE DATASET\n",
    "\n",
    "data = pd.read_csv('Ireland House Price Final.csv')\n",
    "\n",
    "# THIS IS THE BASIC INFORMATION OF THE DATASET\n",
    "print(\"Basic Info:\")\n",
    "data.info()\n",
    "\n",
    "# first few rows\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(data.head())\n",
    "\n",
    "#THIS WILL DISPLAY THE NUMBER OF MISSING VALUES IN THE DATASET\n",
    "print(\"\\nMissing Values Count:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# DISPLAYING THE STATISTICS FOR ALL THE NUMERICALL COLUMNS\n",
    "print(\"\\nSummary Statistics for Numerical Columns:\")\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d8679-4192-4d40-9aba-be0520b0bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IN THIS CODE I WILL BE USING PLOTS TO PLOT FOR NUMERICAL AND CATEGORICAL COLUMNS\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# HERE CONVERTING TOTAL_SQFT COLUMN TO NUMERIC TO PLOT THE GRAPGH EFFECTIVELY\n",
    "data['total_sqft'] = pd.to_numeric(data['total_sqft'], errors='coerce')\n",
    "\n",
    "# 1. Plot for numerical columns\n",
    "numerical_columns = ['total_sqft', 'bath', 'balcony', 'price-per-sqft-$']\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(data[column].dropna(), bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "# 2.categorical columns\n",
    "categorical_columns = ['property_scope', 'location', 'size', 'buying or not buying', 'BER', 'Renovation needed']\n",
    "\n",
    "#PLOT FOR CATEGORICAL COLUMN\n",
    "for column in categorical_columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(data=data, y=column, order=data[column].value_counts().index)\n",
    "    plt.title(f'Count Plot for {column}')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel(column)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536fffeb-42a1-4c70-9983-63c2615057dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IN THIS CODE I WILL BE PERFORMING CORRELATIONS BETWEEN NUMERICAL VARIABLES BEFORE STARTING WITH FURTHER ANALYSIS \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Correlation Between Numerical Variables USING HEATMAP\n",
    "numerical_cols = ['total_sqft', 'bath', 'balcony', 'price-per-sqft-$']\n",
    "correlation_matrix = data[numerical_cols].corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967315f-3a0b-42db-bf11-7e6c69061aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IN THIS PART I HAVE STANDARDIZED ALL THE COLUMNS OF THE DATASET\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Ireland House Price Final.csv')\n",
    "\n",
    "# Step 1: CleanING numerical columns\n",
    "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "def convert_sqft_to_num(sqft):\n",
    "    if isinstance(sqft, str):\n",
    "        if '-' in sqft:\n",
    "            sqft_range = sqft.split('-')\n",
    "            return (float(sqft_range[0]) + float(sqft_range[1])) / 2\n",
    "        else:\n",
    "            try:\n",
    "                return float(sqft)\n",
    "            except ValueError:\n",
    "                return None  # Handle errors gracefully\n",
    "    return sqft\n",
    "\n",
    "\n",
    "#FOR SIZE COLUMN MAKING IT EVEN BY USING REGULAR EXPRESSION\n",
    "def extract_numeric_size(value):\n",
    "    # Use regular expression to extract numbers from the 'size' column\n",
    "    numeric_value = ''.join([char for char in str(value) if char.isdigit()])\n",
    "    return float(numeric_value) if numeric_value else None  \n",
    "    \n",
    "# APPLYING FUNCTION TO THE SIZE COLUMN\n",
    "data['size'] = data['size'].apply(extract_numeric_size)\n",
    "# Clean the numerical columns: convert strings to numbers if needed\n",
    "\n",
    "# Step 1: REMOVING any SPACES IN THE AVAILABILITY COLUMN AND THEN CONVERTING TO LOWER CASE\n",
    "data['availability'] = data['availability'].str.strip().str.lower()\n",
    "\n",
    "# Step 2: REPLACING \"immediate possession\" with \"ready to move\"\n",
    "data['availability'] = data['availability'].replace({\n",
    "    'immediate possession': 'ready to move'\n",
    "})\n",
    "\n",
    "# Step 3: DATES '18-apr', IN AVAILABILITY COLUMN REPLACING WITH MORE MEAINING FULL TERM\n",
    "def handle_date_entries(value):\n",
    "    # Regex to identify date-like strings (e.g., '18-apr', '12-may', etc.)\n",
    "    if isinstance(value, str):\n",
    "        match = re.match(r'(\\d{1,2})-(\\w{3})', value)\n",
    "        if match:\n",
    "            day, month = match.groups()\n",
    "            # REPLACING WITH \"Available in [NAME OF THE MONTH]\" \n",
    "            return f\"Available from {month.capitalize()}\"\n",
    "    return value\n",
    "\n",
    "# Step 2: function to clean the 'availability' column\n",
    "data['availability'] = data['availability'].apply(handle_date_entries)\n",
    "\n",
    "#THE FOLLOWING ARE THE CONVERSION FACTORS TO CONVERT EACH INTO SQUARE FEET UNIT\n",
    "conversion_factors = {\n",
    "    'Acres': 43560,\n",
    "    'Sq. Meter': 10.7639,\n",
    "    'Sq. Yards': 9,\n",
    "    'Cents': 435.6,\n",
    "    'Grounds': 2400,\n",
    "    'Guntha': 1089,\n",
    "    'Perch': 272.25\n",
    "}\n",
    "\n",
    "# Function to convert the units to square feet\n",
    "def convert_to_sqft(value):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub(r'[^\\d.-]', '', value)  \n",
    "        \n",
    "    \n",
    "        if value.endswith('.'):\n",
    "            value = value[:-1]\n",
    "\n",
    "        # IF ITS A RANGE (e.g. '1000 - 1285'), THEN IT WILL SPLIT AND RETURN THE AVERAGE VALUE\n",
    "        if '-' in value:\n",
    "            values = value.split('-')\n",
    "            value1 = convert_single_value(values[0].strip())\n",
    "            value2 = convert_single_value(values[1].strip())\n",
    "            return (value1 + value2) / 2  # Return the average of the two values\n",
    "\n",
    "        # If it's not a range, CONVERTING THE VALUE TO SQFT\n",
    "        return convert_single_value(value)\n",
    "    \n",
    "    return value  # Return the value as-is if it's not a string\n",
    "\n",
    "# Function to convert a single value to square feet based on the unit\n",
    "def convert_single_value(value):\n",
    "    # Check for different units and convert\n",
    "    if 'Acres' in value:\n",
    "        return float(value) * conversion_factors['Acres']\n",
    "    elif 'Sq. Meter' in value:\n",
    "        return float(value) * conversion_factors['Sq. Meter']\n",
    "    elif 'Sq. Yards' in value:\n",
    "        return float(value) * conversion_factors['Sq. Yards']\n",
    "    elif 'Cents' in value:\n",
    "        return float(value) * conversion_factors['Cents']\n",
    "    elif 'Grounds' in value:\n",
    "        return float(value) * conversion_factors['Grounds']\n",
    "    elif 'Guntha' in value:\n",
    "        return float(value) * conversion_factors['Guntha']\n",
    "    elif 'Perch' in value:\n",
    "        return float(value) * conversion_factors['Perch']\n",
    "    else:  # For numeric values without units\n",
    "        return float(value)  # Assume it's in square feet if no unit\n",
    "\n",
    "# Apply conversion to the 'total_sqft' column\n",
    "data['total_sqft'] = data['total_sqft'].apply(convert_to_sqft)\n",
    "\n",
    "\n",
    "\n",
    "# Ensure other numerical columns are numeric\n",
    "data[numerical_columns] = data[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Step 2: Clean categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Clean categorical columns: strip extra spaces and handle inconsistencies\n",
    "data[categorical_columns] = data[categorical_columns].apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
    "\n",
    "data['price-per-sqft-$'] = data['price-per-sqft-$'].round(2)\n",
    "# Step 3: Display the cleaned data\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the summary of the cleaned data\n",
    "print(\"\\nData Info After Cleaning:\")\n",
    "print(data.info())\n",
    "data1 = data.to_csv('standardize.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24e972-6c78-40ec-9b80-b075349ee85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('standardize.csv')\n",
    "\n",
    "print(\"\\nData before outlier removal:\")\n",
    "\n",
    "print(\"\\nBox plot for numeric columns to detect outliers before excluding to fill missing values:\")\n",
    "for col in numeric_columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data[col], orient='h')\n",
    "    plt.title(f'Box Plot of {col} (initial outliers in the dataset)')\n",
    "    plt.xlabel(col)\n",
    "    plt.show()\n",
    "    \n",
    "# Function to detect and remove outliers using the IQR method\n",
    "def remove_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return series[(series >= lower_bound) & (series <= upper_bound)]\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "# Fill missing values for numerical columns with mean or median (excluding outliers)\n",
    "for col in numerical_cols:\n",
    "    if data[col].isnull().sum() > 0:  # Only process columns with missing values\n",
    "        non_null_data = data[col].dropna()  # Remove missing values first\n",
    "        non_outlier_data = remove_outliers(non_null_data)  # Exclude outliers\n",
    "        \n",
    "        # Calculate the mean or median without outliers\n",
    "        if col == 'price-per-sqft-$':  # Example: Use median for specific columns if required\n",
    "            fill_value = non_outlier_data.median()\n",
    "        else:  # Default to mean\n",
    "            fill_value = non_outlier_data.mean()\n",
    "        \n",
    "        # Fill missing values\n",
    "        data[col] = data[col].fillna(fill_value)\n",
    "\n",
    "# Fill missing values for categorical columns with mode (mode doesn't depend on outliers)\n",
    "for col in categorical_cols:\n",
    "    if data[col].isnull().sum() > 0:  # Only process columns with missing values\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])  # Fill with the most frequent value\n",
    "\n",
    "# Save the updated dataset\n",
    "data.to_csv('missing.csv', index=False)\n",
    "\n",
    "# Display a summary of missing values after filling\n",
    "print(\"Missing values after filling:\")\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dfef16-758c-4014-8bba-dafd35eaf2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('missing.csv')\n",
    "\n",
    "# 1. Create a new feature for the total house price if not already present\n",
    "if 'total_price' not in data.columns:\n",
    "    data['total_price'] = data['total_sqft'] * data['price-per-sqft-$']\n",
    "\n",
    "# 3. Save the updated dataset with new features\n",
    "data.to_csv('feature_engineering.csv', index=False)\n",
    "\n",
    "# Display the updated data with new features\n",
    "print(\"New features have been created and saved to 'feature_engineering.csv'.\")\n",
    "print(data.head())  # Preview the updated data with new features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f26a79-d446-4e1d-8602-5b82ab05d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filled missing values excluding outliers and detected outliers before removing missing values\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('missing.csv')\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Function to remove outliers using IQR method\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)  # First quartile\n",
    "    Q3 = df[column].quantile(0.75)  # Third quartile\n",
    "    IQR = Q3 - Q1  # Interquartile range\n",
    "    \n",
    "    # Define bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Filter data\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Remove outliers for each numeric column\n",
    "for col in numeric_columns:\n",
    "    print(f\"Removing outliers in column: {col}\")\n",
    "    data = remove_outliers_iqr(data, col)\n",
    "    \n",
    "data['balcony'] = pd.to_numeric(data['balcony'], errors='coerce').fillna(0).astype(int)\n",
    "data['bath'] = pd.to_numeric(data['bath'], errors='coerce').fillna(0).astype(int)\n",
    "data['size'] = pd.to_numeric(data['size'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Verify the results\n",
    "print(\"\\nData after outlier removal:\")\n",
    "print(data.describe())\n",
    "print(\"\\nBox plot for numeric columns after removing outliers:\")\n",
    "for col in numeric_columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data[col], orient='h')\n",
    "    plt.title(f'Box Plot of {col} (After Outlier Removal)')\n",
    "    plt.xlabel(col)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Save the cleaned data\n",
    "data.to_csv('outliers.csv', index=False)\n",
    "print(\"Cleaned data saved to 'outliers.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c374815-4ea8-4d72-a2e6-dcc25aea01f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearson correlation \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the cleaned dataset\n",
    "data = pd.read_csv('outliers.csv')\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Compute the Pearson correlation matrix\n",
    "correlation_matrix = data[numeric_columns].corr(method='pearson')\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Pearson Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)\n",
    "plt.title(\"Pearson Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc8654e-1d54-4748-9d62-7b3e34fc545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictive analysis techniques used :Random forest, linear regression, SVM to check accuracy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('outliers.csv')\n",
    "\n",
    "# Identify numerical columns and target variable\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "target_col = 'price-per-sqft-$'\n",
    "\n",
    "\n",
    "X = data[numerical_cols].drop(columns=[target_col])  # Features (excluding target)\n",
    "y = data[target_col]  # Target variable\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ----------------- 1. Random Forest Regressor ------------------\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "rf_predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "\n",
    "# ----------------- 2. Linear Regression ------------------\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, lr_predictions))\n",
    "\n",
    "# ----------------- 3. Support Vector Machine (SVM) ------------------\n",
    "\n",
    "svm_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "svm_predictions = svm_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "svm_rmse = np.sqrt(mean_squared_error(y_test, svm_predictions))\n",
    "\n",
    "# ----------------- MAPE Calculation ------------------\n",
    "\n",
    "# Function to calculate MAPE\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    # Avoid division by zero and calculate the percentage error\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Calculate MAPE for all models\n",
    "rf_mape = calculate_mape(y_test, rf_predictions)\n",
    "lr_mape = calculate_mape(y_test, lr_predictions)\n",
    "svm_mape = calculate_mape(y_test, svm_predictions)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Random Forest RMSE: {rf_rmse}\")\n",
    "print(f\"Linear Regression RMSE: {lr_rmse}\")\n",
    "print(f\"SVM RMSE: {svm_rmse}\")\n",
    "\n",
    "print(f\"Random Forest Accuracy (MAPE): {100 - rf_mape:.2f}%\")\n",
    "print(f\"Linear Regression Accuracy (MAPE): {100 - lr_mape:.2f}%\")\n",
    "print(f\"SVM Accuracy (MAPE): {100 - svm_mape:.2f}%\")\n",
    "\n",
    "# ----------------- Save Predictions ------------------\n",
    "\n",
    "data['rf_predicted_price'] = rf_model.predict(scaler.transform(X))  # Random Forest Predictions\n",
    "data['lr_predicted_price'] = lr_model.predict(scaler.transform(X))  # Linear Regression Predictions\n",
    "data['svm_predicted_price'] = svm_model.predict(scaler.transform(X))  # SVM Predictions\n",
    "\n",
    "# Save the updated dataset with predictions\n",
    "data.to_csv('predicted_prices_with_svm.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the data with predictions\n",
    "print(\"\\nData with predictions:\")\n",
    "print(data[['ID', 'price-per-sqft-$', 'rf_predicted_price', 'lr_predicted_price', 'svm_predicted_price']].head())\n",
    "\n",
    "# ----------------- Plot Accuracy Comparison ------------------\n",
    "# Bar chart to compare the accuracy of models\n",
    "models = ['Random Forest', 'Linear Regression', 'SVM']\n",
    "accuracies = [100 - rf_mape, 100 - lr_mape, 100 - svm_mape]  # Accuracy is complement of MAPE\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(models, accuracies, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Accuracy (%)')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlim(0, 100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de1eb9-d8ee-4829-bfed-0b2fd4c1826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictive techniques used : random forest, linear regression, SVM and model accuracy inccreased used pca and hyperparameter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data = pd.read_csv('outliers.csv')\n",
    "\n",
    "# Identify numerical columns and target variable\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "target_col = 'price-per-sqft-$'\n",
    "\n",
    "# Separate features and target\n",
    "X = data[numerical_cols].drop(columns=[target_col])  # Features (excluding target)\n",
    "y = data[target_col]  # Target variable\n",
    "\n",
    "# Apply log transformation for skewed target\n",
    "y = np.log1p(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA \n",
    "pca = PCA(n_components=5) \n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# ----------------- Random Forest with Reduced Hyperparameter Grid ------------------\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "}\n",
    "\n",
    "rf_model = RandomizedSearchCV(RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "                               param_distributions=param_grid_rf,\n",
    "                               n_iter=5,\n",
    "                               cv=2,\n",
    "                               scoring='neg_mean_squared_error',\n",
    "                               random_state=42)\n",
    "rf_model.fit(X_train_pca, y_train)\n",
    "rf_best = rf_model.best_estimator_\n",
    "rf_predictions = np.expm1(rf_best.predict(X_test_pca))  \n",
    "\n",
    "# ----------------- Linear Regression ------------------\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_pca, y_train)\n",
    "lr_predictions = np.expm1(lr_model.predict(X_test_pca))  \n",
    "\n",
    "# ----------------- SVM with Reduced Hyperparameter Grid ------------------\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1],\n",
    "    'kernel': ['linear'],\n",
    "}\n",
    "\n",
    "\n",
    "svm_model = RandomizedSearchCV(SVR(),\n",
    "                                param_distributions=param_grid_svm,\n",
    "                                n_iter=2,  \n",
    "                                cv=2,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                random_state=42)\n",
    "svm_model.fit(X_train_pca, y_train)\n",
    "svm_best = svm_model.best_estimator_\n",
    "svm_predictions = np.expm1(svm_best.predict(X_test_pca))  \n",
    "\n",
    "# ----------------- Evaluation ------------------\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    accuracy = 100 - mape  # Accuracy as complement of MAPE\n",
    "    print(f\"{model_name} RMSE: {rmse:.2f}\")\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.2f}%\")\n",
    "    return rmse, accuracy\n",
    "\n",
    "y_test_exp = np.expm1(y_test)  \n",
    "\n",
    "rf_rmse, rf_accuracy = evaluate_model(y_test_exp, rf_predictions, \"Random Forest\")\n",
    "lr_rmse, lr_accuracy = evaluate_model(y_test_exp, lr_predictions, \"Linear Regression\")\n",
    "svm_rmse, svm_accuracy = evaluate_model(y_test_exp, svm_predictions, \"SVM\")\n",
    "\n",
    "# ----------------- Save Predictions ------------------\n",
    "data['rf_predicted_price'] = np.expm1(rf_best.predict(pca.transform(scaler.transform(X))))\n",
    "data['lr_predicted_price'] = np.expm1(lr_model.predict(pca.transform(scaler.transform(X))))\n",
    "data['svm_predicted_price'] = np.expm1(svm_best.predict(pca.transform(scaler.transform(X))))\n",
    "\n",
    "data.to_csv('optimized_predictions_fast.csv', index=False)\n",
    "\n",
    "print(\"\\nOptimized predictions saved to 'optimized_predictions_fast.csv'.\")\n",
    "\n",
    "# ----------------- Plot Accuracy Comparison ------------------\n",
    "# Bar chart to compare the accuracy of models\n",
    "models = ['Random Forest', 'Linear Regression', 'SVM']\n",
    "accuracies = [rf_accuracy, lr_accuracy, svm_accuracy]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(models, accuracies, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Accuracy (%)')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4005c2e-b016-4d59-83b3-e28c78c395d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
